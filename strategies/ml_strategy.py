import pandas as pd
from sklearn.ensemble import RandomForestClassifier

from strategies.base import BaseStrategy


class MLStrategy(BaseStrategy):
    def __init__(
        self, symbols: list, train_size: float = 0.8, prob_threshold: float = 0.6
    ):
        """
        :param train_size: ç”¨äºè®­ç»ƒçš„æ•°æ®æ¯”ä¾‹ï¼ˆå‰ 80% è®­ç»ƒï¼Œå 20% å›æµ‹é¢„æµ‹ï¼‰
        :param prob_threshold: ä¹°å…¥çš„æ¦‚ç‡é˜ˆå€¼
        """
        super().__init__("Machine_Learning_Strategy", symbols)
        self.feature_order = None
        self.params = {"train_size": train_size, "prob_threshold": prob_threshold}
        self.models = {}  # ä¸ºæ¯åªè‚¡ç¥¨å­˜å‚¨ç‹¬ç«‹çš„æ¨¡å‹

    @staticmethod
    def _prepare_features(df: pd.DataFrame):
        """æå–ç‰¹å¾åˆ—ï¼Œå‰”é™¤ä»·æ ¼å’Œå…ƒæ•°æ®"""
        exclude = ["Open", "High", "Low", "Close", "Volume", "Signal", "Target"]
        # è¿˜è¦æ’é™¤æ‰åé¢è®¡ç®—äº§ç”Ÿçš„å›æµ‹åˆ—
        exclude += [
            "Market_Return",
            "Strategy_Return",
            "Position",
            "Trades",
            "Cumulative_Return",
            "Equity_Curve",
            "Peak",
            "Drawdown",
        ]
        features = [col for col in df.columns if col not in exclude]
        return features

    def on_data(self, symbol: str, df: pd.DataFrame) -> pd.DataFrame:
        df = df.copy()
        df["Signal"] = 0

        # 1. å‡†å¤‡ç›®æ ‡æ ‡ç­¾ (æœªæ¥ 5 å¤©æ˜¯å¦ä¸Šæ¶¨)
        df["Target"] = (df["Close"].shift(-5) > df["Close"]).astype(int)
        features = self._prepare_features(df)

        # æ¸…ç†ç©ºå€¼
        clean_df = df.dropna(subset=features + ["Target"])

        # 2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† (æŒ‰æ—¶é—´é¡ºåº)
        split_idx = int(len(clean_df) * self.params["train_size"])
        train_df = clean_df.iloc[:split_idx]
        test_df = clean_df.iloc[split_idx:]

        if len(train_df) < 100:
            print(f"âš ï¸ {symbol} æ•°æ®é‡å¤ªå°ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
            return df

        # 3. è®­ç»ƒæ¨¡å‹
        print(
            f"ğŸ¤– [{symbol}] æ­£åœ¨è®­ç»ƒ AI æ¨¡å‹... æ ·æœ¬æ•°: {len(train_df)}, ç‰¹å¾æ•°: {len(features)}"
        )
        X_train = train_df[features]
        y_train = train_df["Target"]

        # è®°å½•è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåºï¼Œç¡®ä¿é¢„æµ‹æ—¶å®Œå…¨ä¸€è‡´
        self.feature_order = features.copy()

        model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
        model.fit(X_train, y_train)
        self.models[symbol] = model  # æŒä¹…åŒ–æ¨¡å‹

        # 4. é¢„æµ‹ (åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šç”Ÿæˆæ¦‚ç‡ï¼Œæˆ–ä»…åœ¨æµ‹è¯•é›†ç”Ÿæˆ)
        # ä¸ºäº†å›æµ‹å±•ç¤ºå®Œæ•´æ€§ï¼Œæˆ‘ä»¬åœ¨æµ‹è¯•é›†ä¸Šåº”ç”¨ä¿¡å·
        X_test = test_df[features]
        # è·å–é¢„æµ‹ä¸º '1' (æ¶¨) çš„æ¦‚ç‡
        probs = model.predict_proba(X_test)[:, 1]

        # 5. ç”Ÿæˆä¿¡å·ï¼šæ¦‚ç‡ > é˜ˆå€¼åˆ™ä¹°å…¥ (1)ï¼Œå¦åˆ™è§‚æœ› (0)
        # æˆ‘ä»¬æš‚æ—¶ä¸è®¾å–å‡ºä¿¡å· (-1)ï¼Œç”± BacktestEngine çš„æŒä»“é€»è¾‘è‡ªåŠ¨å¤„ç†
        test_signals = (probs > self.params["prob_threshold"]).astype(int)
        print(
            f"ğŸ“ˆ [{symbol}] é¢„æµ‹å®Œæˆï¼Œæœ€å¤§ä¸Šæ¶¨æ¦‚ç‡: {probs.max():.2%}, äº§ç”Ÿä¿¡å·æ•°: {sum(test_signals)}"
        )

        # å°†ä¿¡å·å¡«å›åŸ DataFrame (å¯¹åº”æµ‹è¯•é›†ä½ç½®)
        df.loc[test_df.index, "Signal"] = test_signals

        return df
